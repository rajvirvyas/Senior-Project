{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMcgDNYjCORO3q6n5NLdiv1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajvirvyas/Senior-Project/blob/main/Image_Processing_PRETRAINED_approach.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CNN approach using Kaggle Dataset**"
      ],
      "metadata": {
        "id": "vWRhhHz1c2G2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, I will need to use data generators to load images from the directories for training, testing and validation."
      ],
      "metadata": {
        "id": "w_JayhSuc9CH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ[\"KAGGLE_KEY\"] = userdata.get('KAGGLE_KEY')\n",
        "os.environ[\"KAGLE_USR\"] = userdata.get('KAGGLE_USR')"
      ],
      "metadata": {
        "id": "SerbwlAsjV1C"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d marcozuppelli/stegoimagesdataset\n",
        "\n",
        "! unzip -qq \"stegoimagesdataset.zip\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOVagdchjhRF",
        "outputId": "5d55bbf6-a9c6-4ca3-b29c-007d16114d97"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/marcozuppelli/stegoimagesdataset\n",
            "License(s): DbCL-1.0\n",
            "Downloading stegoimagesdataset.zip to /content\n",
            "100% 1.51G/1.51G [00:13<00:00, 210MB/s]\n",
            "100% 1.51G/1.51G [00:13<00:00, 118MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import random\n",
        "\n",
        "def logistic_map(x,r):\n",
        "    return r * x * (1-x)\n",
        "\n",
        "def generate_time_series(size,r=5.2, seed=0.5):\n",
        "    x = seed # common seed\n",
        "    time_series = [x]\n",
        "\n",
        "    for _ in range(size - 1):\n",
        "        x = logistic_map(x,r) # r can be chosen to be any num\n",
        "        x = (x- np.floor(x)) #limit between 0 and 1\n",
        "        time_series.append(x)\n",
        "\n",
        "    return np.array(time_series)\n",
        "\n",
        "def apply_noise(binary_secret, noisy_time_series):\n",
        "    blist = list(binary_secret)\n",
        "    binary_length = len(blist)\n",
        "\n",
        "    for i in range (binary_length):\n",
        "        bit = int(blist[i])\n",
        "        magic_num = noisy_time_series[i % len(noisy_time_series)]\n",
        "        bit = bit ^ int(magic_num * 2) #xor\n",
        "        blist[i] = str(bit)\n",
        "\n",
        "    return \"\".join(blist)\n",
        "\n",
        "def extract_noise(imagepath, size):\n",
        "    image = Image.open(imagepath)\n",
        "    width, height = image.size\n",
        "    noisy_secret = ''\n",
        "    n = 0\n",
        "\n",
        "    for i in range(0, width):\n",
        "        for j in range(0, height):\n",
        "            pixel = list(image.getpixel((i, j)))\n",
        "            for val in range(0, 3):\n",
        "                if n < size:\n",
        "                    noisy_secret += str(pixel[val] & 1)\n",
        "                    n += 1\n",
        "                else:\n",
        "                    break\n",
        "            if n >= size:\n",
        "                break\n",
        "        if n >= size:\n",
        "            break\n",
        "\n",
        "    return noisy_secret.zfill(size)\n"
      ],
      "metadata": {
        "id": "Fi1zkQ2IdOTC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_chaotic_noise_to_dataset(stego_image):\n",
        "  lsb_data = ''.join(str(pixel & 1) for pixel in stego_image.flat)\n",
        "  noisy_time_series = generate_time_series(len(lsb_data))\n",
        "  noisy_lsb_data = apply_noise(lsb_data, noisy_time_series)\n",
        "\n",
        "  noisy_stego_image = stego_image.copy() #put noisy data into image again\n",
        "  for i in range(len(noisy_lsb_data)):\n",
        "    noisy_stego_image.flat[i] = (noisy_stego_image.flat[i] & ~1) | int(noisy_lsb_data[i])\n",
        "\n",
        "  return noisy_stego_image"
      ],
      "metadata": {
        "id": "sarzPijreoXI"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ok, now that I have functions for doing all this fuss, lets run the noisy embedding on the kaggle dataset"
      ],
      "metadata": {
        "id": "YGxQvTIlhOmW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "def convert_to_noisy_embeddings(input_dir, output_dir):\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    for filename in tqdm(os.listdir(input_dir), desc=\"Processing images\"):\n",
        "        if filename.endswith(\".png\"):\n",
        "            image_path = os.path.join(input_dir, filename)\n",
        "            stego_image = cv2.imread(image_path)\n",
        "\n",
        "            noisy_stego_image = add_chaotic_noise_to_dataset(stego_image)\n",
        "            output_path = os.path.join(output_dir, filename)\n",
        "            cv2.imwrite(output_path, noisy_stego_image)\n"
      ],
      "metadata": {
        "id": "hrue0lhkhYKE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "convert_to_noisy_embeddings('/content/train/train/stego', '/content/train/train/noisy_stego')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "xYbjLOslin6P",
        "outputId": "ab6047a9-6e10-478e-9674-f96ff484c4b3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing images:   0%|          | 20/12000 [02:15<22:34:38,  6.78s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-96c7479695d1>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconvert_to_noisy_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/train/train/stego'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/content/train/train/noisy_stego'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-258d7269d634>\u001b[0m in \u001b[0;36mconvert_to_noisy_embeddings\u001b[0;34m(input_dir, output_dir)\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mstego_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mnoisy_stego_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_chaotic_noise_to_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstego_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0moutput_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoisy_stego_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-370af3e6c9f1>\u001b[0m in \u001b[0;36madd_chaotic_noise_to_dataset\u001b[0;34m(stego_image)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mlsb_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpixel\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpixel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstego_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mnoisy_time_series\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_time_series\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlsb_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mnoisy_lsb_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_noise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlsb_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoisy_time_series\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mnoisy_stego_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstego_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#put noisy data into image again\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-d73a6ebda783>\u001b[0m in \u001b[0;36mapply_noise\u001b[0;34m(binary_secret, noisy_time_series)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbinary_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mbit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mmagic_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnoisy_time_series\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoisy_time_series\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mbit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbit\u001b[0m \u001b[0;34m^\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_num\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#xor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def make_data_generators(train_dir, val_dir, batch_size=32,epochs=10):\n",
        "  train_datagen = ImageDataGenerator(rescale= 1./255)  # applied normalization of pixel values\n",
        "  train_generator = train_datagen.flow_from_directory(\n",
        "      '/content/train/train', #training directory\n",
        "      target_size= (128, 128),\n",
        "      batch_size= batch_size,\n",
        "      class_mode= 'binary'\n",
        "  )\n",
        "\n",
        "  validation_datagen = ImageDataGenerator(rescale= 1./255)  # applied normalization of pixel values\n",
        "  validation_generator = validation_datagen.flow_from_directory(\n",
        "      '/content/val', #validation directory\n",
        "      target_size= (128, 128),\n",
        "      batch_size= batch_size,\n",
        "      class_mode= 'binary'\n",
        "  )\n",
        "\n",
        "  # testing_datagen = ImageDataGenerator(rescale= 1./255)  # applied normalization of pixel values\n",
        "  # testing_generator = testing_datagen.flow_from_directory(\n",
        "  #     '', #training directory\n",
        "  #     target_size= (128, 128),\n",
        "  #     batch_size= 32,\n",
        "  #     class_mode= 'binary'\n",
        "  # )\n",
        "  return train_generator, validation_generator\n",
        "\n",
        "def get_class_weights(train_generator):\n",
        "  classes = np.array([0] * train_generator.classes.shape[0])\n",
        "  for i in range(len(train_generator.classes)):\n",
        "    classes[i] = train_generator.classes[i]\n",
        "  class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(classes), y=classes)\n",
        "  class_weights = dict(enumerate(class_weights))\n",
        "  return class_weights\n",
        "\n",
        "def training_steganography_model(model, train_dir, val_dir, epochs=10):\n",
        "  early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "  lr_reducer = ReduceLROnPlateau(factor=0.2, patience=3, min_lr=0.00001)\n",
        "\n",
        "  train_generator, validation_generator = make_data_generators(train_dir, val_dir, epochs)\n",
        "  class_weights = get_class_weights(train_generator)\n",
        "\n",
        "  history =model.fit(\n",
        "      train_generator,\n",
        "      epochs=epochs,\n",
        "      validation_data = validation_generator,\n",
        "      callbacks=[early_stop, lr_reducer],\n",
        "      class_weight=class_weights\n",
        "  )\n",
        "  return history\n",
        "\n",
        "def fine_tuning_model(model, train_generator, validation_generator, epochs=10):\n",
        "  for layer in model.layers[-15:]:\n",
        "    layer.trainable = True\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  history = model.fit(\n",
        "      train_generator,\n",
        "      epochs=epochs,\n",
        "      validation_data = validation_generator,\n",
        "      callbacks=[EarlyStopping(patience=3, restore_best_weights=True)]\n",
        "  )\n",
        "  return history\n",
        "\n"
      ],
      "metadata": {
        "id": "FD8bkofelcnm"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ok lets try using resnet50"
      ],
      "metadata": {
        "id": "TAkkd-LGkEhV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import ResNet50, VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.utils import class_weight\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "def build_classificaton_model(model_type,shape):\n",
        "    if model_type == 'resnet50':\n",
        "      base_model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=shape)\n",
        "    else:\n",
        "      base_model = tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=shape)\n",
        "\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(1024, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    predictions = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "Oz-3D3NWmSlu"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_type = 'resnet50'\n",
        "model = build_classificaton_model(model_type,(128,128,3))\n",
        "#model.summary()\n",
        "train_generator, validation_generator = make_data_generators('/content/train/train', '/content/val', batch_size=16, epochs=10)\n",
        "history = training_steganography_model(model, train_generator, validation_generator, epochs=10)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 716
        },
        "id": "60jtTizammfa",
        "outputId": "829eb90d-ca8b-4a1d-a380-b10e9021c212"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 16000 images belonging to 2 classes.\n",
            "Found 8000 images belonging to 1 classes.\n",
            "Found 16000 images belonging to 2 classes.\n",
            "Found 8000 images belonging to 1 classes.\n",
            "Epoch 1/10\n",
            "1600/1600 [==============================] - 134s 80ms/step - loss: 2.6753 - accuracy: 0.4941 - val_loss: 1.8159 - val_accuracy: 0.0185 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1600/1600 [==============================] - 125s 78ms/step - loss: 1.1307 - accuracy: 0.4901 - val_loss: 1.4215 - val_accuracy: 0.0030 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1600/1600 [==============================] - 131s 82ms/step - loss: 0.9751 - accuracy: 0.4837 - val_loss: 3.2001 - val_accuracy: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1600/1600 [==============================] - 181s 113ms/step - loss: 0.8794 - accuracy: 0.5074 - val_loss: 0.7849 - val_accuracy: 0.4429 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1600/1600 [==============================] - 140s 87ms/step - loss: 0.8321 - accuracy: 0.4848 - val_loss: 1.1540 - val_accuracy: 0.0140 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1600/1600 [==============================] - 134s 84ms/step - loss: 0.7937 - accuracy: 0.4934 - val_loss: 0.8471 - val_accuracy: 0.1416 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1600/1600 [==============================] - 135s 84ms/step - loss: 0.7670 - accuracy: 0.4921 - val_loss: 0.8766 - val_accuracy: 0.1181 - lr: 1.0000e-04\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'Functional' object has no attribute 'layer'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-1e8230c3f997>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_steganography_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mfinetuned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfine_tuning_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-16-0b34d6b3ab20>\u001b[0m in \u001b[0;36mfine_tuning_model\u001b[0;34m(model, train_generator, validation_generator, epochs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfine_tuning_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.00001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Functional' object has no attribute 'layer'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "finetuned = fine_tuning_model(model, train_generator, validation_generator, epochs=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nox6yKOk1Rrm",
        "outputId": "c10997e0-90d2-45cd-8a0d-0234d8b834d3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1000/1000 [==============================] - 132s 124ms/step - loss: 0.8432 - accuracy: 0.5253 - val_loss: 0.8439 - val_accuracy: 0.4658\n",
            "Epoch 2/10\n",
            "1000/1000 [==============================] - 125s 125ms/step - loss: 0.7752 - accuracy: 0.6162 - val_loss: 0.9322 - val_accuracy: 0.2962\n",
            "Epoch 3/10\n",
            "1000/1000 [==============================] - 126s 126ms/step - loss: 0.7335 - accuracy: 0.6829 - val_loss: 1.4672 - val_accuracy: 5.0000e-04\n",
            "Epoch 4/10\n",
            "1000/1000 [==============================] - 129s 129ms/step - loss: 0.7059 - accuracy: 0.7172 - val_loss: 1.4291 - val_accuracy: 0.0135\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_type = 'vgg16'\n",
        "model = build_classificaton_model(model_type,(128,128,3))\n",
        "#model.summary()\n",
        "train_generator, validation_generator = make_data_generators('/content/train/train', '/content/val', batch_size=16, epochs=10)\n",
        "history = training_steganography_model(model, train_generator, validation_generator, epochs=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlZIV5b4mUUC",
        "outputId": "ef5a4fe0-908f-41b1-f106-b1b52c6733e8"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n",
            "Found 16000 images belonging to 2 classes.\n",
            "Found 8000 images belonging to 1 classes.\n",
            "Found 16000 images belonging to 2 classes.\n",
            "Found 8000 images belonging to 1 classes.\n",
            "Epoch 1/10\n",
            "1600/1600 [==============================] - 130s 79ms/step - loss: 3.6793 - accuracy: 0.4919 - val_loss: 2.1716 - val_accuracy: 0.7111 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "1600/1600 [==============================] - 123s 77ms/step - loss: 2.0274 - accuracy: 0.4927 - val_loss: 1.7693 - val_accuracy: 0.4857 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "1600/1600 [==============================] - 119s 75ms/step - loss: 1.5107 - accuracy: 0.4869 - val_loss: 1.1419 - val_accuracy: 0.8100 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "1600/1600 [==============================] - 118s 74ms/step - loss: 1.2190 - accuracy: 0.4906 - val_loss: 0.9698 - val_accuracy: 0.7063 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "1600/1600 [==============================] - 118s 74ms/step - loss: 1.0388 - accuracy: 0.4800 - val_loss: 1.1300 - val_accuracy: 0.1468 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1600/1600 [==============================] - 117s 73ms/step - loss: 0.9183 - accuracy: 0.4865 - val_loss: 0.7066 - val_accuracy: 0.8356 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1600/1600 [==============================] - 118s 74ms/step - loss: 0.8413 - accuracy: 0.4847 - val_loss: 0.8461 - val_accuracy: 0.3524 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1600/1600 [==============================] - 125s 78ms/step - loss: 0.7915 - accuracy: 0.4854 - val_loss: 0.7311 - val_accuracy: 0.5543 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1600/1600 [==============================] - 118s 73ms/step - loss: 0.7561 - accuracy: 0.4902 - val_loss: 0.6294 - val_accuracy: 0.8589 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1600/1600 [==============================] - 125s 78ms/step - loss: 0.7316 - accuracy: 0.4856 - val_loss: 0.6183 - val_accuracy: 0.9728 - lr: 1.0000e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "finetuned = fine_tuning_model(model, train_generator, validation_generator, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQ8bOuTU84QK",
        "outputId": "2483773f-d57a-45bf-df35-23424bcff947"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1000/1000 [==============================] - 127s 120ms/step - loss: 0.6945 - accuracy: 0.6582 - val_loss: 0.8055 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "1000/1000 [==============================] - 122s 122ms/step - loss: 0.6397 - accuracy: 0.7500 - val_loss: 1.0068 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "1000/1000 [==============================] - 122s 122ms/step - loss: 0.5977 - accuracy: 0.7500 - val_loss: 1.1138 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "1000/1000 [==============================] - 121s 121ms/step - loss: 0.5769 - accuracy: 0.7500 - val_loss: 1.2375 - val_accuracy: 0.0000e+00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DO NOT USE THE FOLLOWING CODE**"
      ],
      "metadata": {
        "id": "_8m1Xe4jSp9s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import layers,models\n",
        "\n",
        "def CNN_algorithm(shape):\n",
        "  model = models.Sequential()\n",
        "  model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=shape))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(128, activation='relu'))\n",
        "  model.add(layers.Dense(1, activation='sigmoid'))\n",
        "  #model.summary()\n",
        "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "model=CNN_algorithm((128,128,3))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEfq8Tjedt0K",
        "outputId": "ab83613f-0205-4a46-eeb9-e9ea034d4aa2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 126, 126, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 63, 63, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 61, 61, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 30, 30, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 28, 28, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 14, 14, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               3211392   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3304769 (12.61 MB)\n",
            "Trainable params: 3304769 (12.61 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history =model.fit(\n",
        "    train_generator,\n",
        "    epochs=10,\n",
        "    validation_data = validation_generator\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hk5sIRMakkQu",
        "outputId": "75960111-41f2-4255-f88b-3c65b38ec003"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "500/500 [==============================] - 114s 217ms/step - loss: 0.5738 - accuracy: 0.7492 - val_loss: 1.3296 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "500/500 [==============================] - 107s 213ms/step - loss: 0.5646 - accuracy: 0.7500 - val_loss: 1.3575 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "500/500 [==============================] - 108s 215ms/step - loss: 0.5638 - accuracy: 0.7500 - val_loss: 1.5459 - val_accuracy: 0.0000e+00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I observed that accuracy doesn't really change and my val_accuracy stays 0. I think it might be worth looking into a different number of layers, or different optimizer or learning rate as well. Also, maybe I need to shuffle the dataset?"
      ],
      "metadata": {
        "id": "DLROmo7_ooze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def count_images(directory):\n",
        "    count = 0\n",
        "    for subdir, _, files in os.walk(directory):\n",
        "        count += len(files)\n",
        "    return count\n",
        "\n",
        "print(\"Training cover images:\", count_images(os.path.join('/content/train/train', 'clean')))\n",
        "print(\"Training stego images:\", count_images(os.path.join('/content/train/train', 'stego')))\n",
        "#print(\"Validation cover images:\", count_images(os.path.join(val_dir, 'cover')))\n",
        "#print(\"Validation stego images:\", count_images(os.path.join(val_dir, 'stego')))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caasYV2Vn108",
        "outputId": "a5d85179-625c-4a1a-d6a4-246fce69ab89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training cover images: 4000\n",
            "Training stego images: 12000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is an issue of data imbalance: 4000 cover images for 12000 stego images;\n",
        "This can cause my model to work poorly due to biased training."
      ],
      "metadata": {
        "id": "WX5MaQLToTG1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before addressing this issue, I need to address that the benchmark paper also utilized a deep learning approach using neural networks in order to detect stego, but their model has some finetuning I must be missing since they got about 99.2% accuracy."
      ],
      "metadata": {
        "id": "070VCj7volbm"
      }
    }
  ]
}